{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f442e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "99b8eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keys\n",
    "API_KEY = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "90f3b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(SEARCH_QUERY, MAX_RESULTS):\n",
    "    channels = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(channels) < MAX_RESULTS:\n",
    "        url = f'https://www.googleapis.com/youtube/v3/search?key={API_KEY}&q={SEARCH_QUERY}&type=channel&part=id&maxResults={MAX_RESULTS}&pageToken={next_page_token}' if next_page_token else f'https://www.googleapis.com/youtube/v3/search?key={API_KEY}&q={SEARCH_QUERY}&type=channel&part=id&maxResults={MAX_RESULTS}'\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            if 'items' in data:\n",
    "                channels.extend([item['id']['channelId'] for item in data['items']])\n",
    "\n",
    "            if 'nextPageToken' in data:\n",
    "                next_page_token = data['nextPageToken']\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    #print(f\"Total channels retrieved: {len(channels)}\")\n",
    "    #print(channels)\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "61c7fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_video_details(video_id):\n",
    "\n",
    "    #collecting view, like, dislike, comment counts\n",
    "    url_video_stats = \"https://www.googleapis.com/youtube/v3/videos?id=\"+video_id+\"&part=statistics&key=\"+API_KEY\n",
    "    response_video_stats = requests.get(url_video_stats).json()\n",
    "\n",
    "    #view_count = response_video_stats['items'][0]['statistics']['viewCount']\n",
    "    #like_count = response_video_stats['items'][0]['statistics']['likeCount']\n",
    "    \n",
    "    # Check if 'dislikeCount' key is present in the response, otherwise set to 0\n",
    "    if 'dislikeCount' in response_video_stats['items'][0]['statistics']:\n",
    "        dislike_count = response_video_stats['items'][0]['statistics']['dislikeCount']\n",
    "    else:\n",
    "        dislike_count = 0\n",
    "        \n",
    "    # Check if 'commentcount' key is present in the response, otherwise set to 0\n",
    "    if 'commentCount' in response_video_stats['items'][0]['statistics']:\n",
    "         comment_count = response_video_stats['items'][0]['statistics']['commentCount']\n",
    "    else:\n",
    "        comment_count = 0\n",
    "        \n",
    "        # Check if 'commentcount' key is present in the response, otherwise set to 0\n",
    "    if 'likeCount' in response_video_stats['items'][0]['statistics']:\n",
    "         like_count = response_video_stats['items'][0]['statistics']['likeCount']\n",
    "    else:\n",
    "        like_count = 0       \n",
    "        \n",
    "        # Check if 'commentcount' key is present in the response, otherwise set to 0\n",
    "    if 'viewCount' in response_video_stats['items'][0]['statistics']:\n",
    "         view_count = response_video_stats['items'][0]['statistics']['viewCount']\n",
    "    else:\n",
    "        like_count = 0      \n",
    "    #comment_count = response_video_stats['items'][0]['statistics']['commentCount']\n",
    "\n",
    "    return view_count, like_count, dislike_count, comment_count\n",
    "    #dislike_count = response_video_stats['items'][0]['statistics']['dislikeCount']\n",
    "    #comment_count = response_video_stats['items'][0]['statistics']['commentCount']\n",
    "\n",
    "    #return view_count, like_count, dislike_count, comment_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6e25fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(df, CHANNEL_ID, MAX_RESULTS):\n",
    "    pageToken = \"\"\n",
    "    all_data = []  # Initialize a list to store video data\n",
    "    \n",
    "    url = \"https://www.googleapis.com/youtube/v3/search?key=\"+API_KEY+\"&channelId=\"+CHANNEL_ID+\"&part=snippet,id&order=date&maxResults=\"+str(MAX_RESULTS)+\"&\"+pageToken\n",
    "\n",
    "    response = requests.get(url).json()\n",
    "    time.sleep(1)  # Give it a second before starting the for loop\n",
    "\n",
    "    for video in response['items']:\n",
    "        if video['id']['kind'] == \"youtube#video\":\n",
    "            video_id = video['id']['videoId']\n",
    "            video_title = video['snippet']['title']\n",
    "            video_title = str(video_title).replace(\"&\", \"\")\n",
    "            upload_date = video['snippet']['publishedAt']\n",
    "            upload_date = str(upload_date).split(\"T\")[0]\n",
    "            view_count, like_count, dislike_count, comment_count = get_video_details(video_id)\n",
    "\n",
    "            video_data = {\n",
    "                'channel_id': CHANNEL_ID,\n",
    "                'video_id': video_id,\n",
    "                'video_title': video_title,\n",
    "                'upload_date': upload_date,\n",
    "                'view_count': view_count,\n",
    "                'like_count': like_count,\n",
    "                'dislike_count': dislike_count,\n",
    "                'comment_count': comment_count\n",
    "            }\n",
    "            all_data.append(video_data)\n",
    "                \n",
    "    new_df = pd.DataFrame(all_data)  # Create a DataFrame from the collected data\n",
    "    df = pd.concat([df, new_df], ignore_index=True)  # Concatenate the new data with the existing DataFrame\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a6bae8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "\n",
    "search_queries = ['arsenal', 'barcelona', 'chelsea']\n",
    "\n",
    "for SEARCH_QUERY in search_queries:\n",
    "    #build our dataframe\n",
    "    df2 = pd.DataFrame(columns=[\"channel_id\",\"video_id\",\"video_title\",\"upload_date\",\"view_count\",\"like_count\",\"dislike_count\",\"comment_count\"]) \n",
    "\n",
    "    channels = get_channels(SEARCH_QUERY, 1)\n",
    "\n",
    "    for channel_id in channels:\n",
    "        df2 = get_videos(df2, channel_id, 5)\n",
    "    \n",
    "    search_query_name = SEARCH_QUERY.replace(\" \", \"\")\n",
    "    df2.to_csv(f'youtube_vids_{search_query_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32f5478c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c7572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2eaa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a759b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
